# Quantized Face Detection using SeeDot

Face detection using SeeDot can be performed on the `face-2` and `face-4` datasets, which are processed subsets of the [SCUT Head Part B](https://github.com/HCIILAB/SCUT-HEAD-Dataset-Release) dataset.

Face detection is a regression problem that involves an image input with (or without) faces and bounding boxes around the faces as output. 
Face detection is supported for x86 and ARM Cortex-M3 target devices.  

### Obtaining the Datasets
To obtain the model weights and datasets for the face detection problem, run `fetchFDDataset.py` in `seedot/compiler/input/` folder.
Or simply run the following commands from SeeDot's home directory (`EdgeML/tools/SeeDot/`):
```
    cd seedot/compiler/input/
    python fetchFDDataset.py
    cd ../../..
```

This python script will place the model weights in `model/rnnpool/face-2/` for the `face-2` dataset and in `model/rnnpool/face-4/` for the `face-4` dataset.
The datasets are placed in `datasets/rnnpool/face-2/` for the `face-2` dataset and in `datasets/rnnpool/face-4/` for the `face-4` dataset.

### Run Face Detection for x86
To run face detection using the SeeDot quantizer on x86 devices, run the following command: 

```
    python SeeDot-dev.py -a rnnpool -e fixed -m disagree -d face-2 -dt testing -t x86 -n 18000 
```
for the `face-2` dataset, and:
```
    python SeeDot-dev.py -a rnnpool -e fixed -m disagree -d face-4 -dt testing -t x86 -n 18000 
```
for the `face-4` dataset.

The non-optional arguments used in the above commands are:
```
    Argument            Value       Description
    
    -a, --algo          rnnpool     Face detection problem uses the 'rnnpool' machine learning
                                    algorithm.

    -e, --encoding      fixed/      The encoding to use for face detection. 
                        float       The options are 'float' and 'fixed'.

    -m, --metric        disagree    The metric used to measure correctness of prediction.
                                    This is used for quantization. 

    -d, --dataset       face-2/     The dataset to use for face detection. 
                        face-4      The options are 'face-2' and 'face-4'.
    
    -dt, --datesetType  training/   The type of the dataset to use for quantization. 
                        testing     The options are 'training' and 'testing'.
                                    Default is 'testing'.

    -t, --target        x86         The target device for which the code has to be generated. 
                                    'x86' in this case.

    -n, --numOutputs    18000       The size of the output vector of rnnpool face detection
                                    algorithm.
                      
```
The output will be stored in the `temp/` directory by default. Use the `-o <destination folder>` flag to store the output to an already existing location. 

### Run Face Detection for M3
To run face detection using the SeeDot quantizer for M3 device, run the command: 

```
    python SeeDot-dev.py -a rnnpool -e fixed -m disagree -d face-2 -dt testing -t m3 -n 18000 
```
for the `face-2` dataset, and:
```
    python SeeDot-dev.py -a rnnpool -e fixed -m disagree -d face-4 -dt testing -t m3 -n 18000 
```
for the `face-4` dataset.

Note: The target device specified using the `-t` argument has the value `m3` in this case. See above for a detailed argument description.

The output will be stored in the `m3dump/` directory by default. Use the `-o <destination folder>` flag to store the output to an already existing location. 

## Run SeeDot's Output - Quantized Prediction Code

This section discusses the execution of the quantized fixed-point model generated by SeeDot on 
random images from the [SCUT Head Part B](https://github.com/HCIILAB/SCUT-HEAD-Dataset-Release) dataset.

### Library Installation
This section requires installing `pytorch`, `cv2`, `easydict`, and `six` python libraries. Run the following commands for installing them:
```
    pip install torch==1.5.1+cpu torchvision==0.6.1+cpu -f https://download.pytorch.org/whl/torch_stable.html
    pip install opencv-python
    pip install easydict
    pip install six
```

### Running Face Detection on Image Input

By default, the quantized `x86` codes are stored in the `temp/` directory. 

To run the model, we use the `Predictor` executable in the `temp/Predictor`directory.

First, we need to download an image to test the quantized `Predictor`.

For that, we follow the below steps:
```
    cd faceDetection/
    mkdir -p images/
    cd images/
    wget https://github.com/krantikiran68/EdgeML/raw/newer-seedot/tools/SeeDot/fdTestImg.jpg
    cd ..
    cp -r ../../../examples/pytorch/vision/Face_Detection/layers/ .
    cp -r ../../../examples/pytorch/vision/Face_Detection/utils/ .
    mkdir -p data/
    cp -r ../../../examples/pytorch/vision/Face_Detection/data/choose_config.py data/
    cp -r ../../../examples/pytorch/vision/Face_Detection/data/config_qvga.py data/
```

Note: The last 5 commands copy scripts from another location of this repository, to help in the conversion of images to text files and vice-versa. 

This will download `fdTestImg.jpg` to the `images/` directory. Users can use their own images as well instead of wget.
Multiple images can be added to the `images/` directory, which will be processed in a single execution.  

Note that we run all of the following python scripts in the `SeeDot/faceDetection` directory. 

To create the files used by `Predictor` from the set of images, we run the following command:

```
    python scale_image.py --image_dir images/ --out_dir input/
```

The script `scale_image.py` reads all the images in the `images/` directory (which is the default for the `image_dir` field). 
And outputs the files `X.csv` and `Y.csv` in the `input/` directory (which is the default for the `out_dir` field). 

Now, we copy the executable to this directory and run it using the below commands:
```
    cp ../temp/Predictor/Predictor .
    mkdir -p input/
    mkdir -p output/
    ./Predictor fixed testing regression 18000 False
```

For running the executable, specifying all arguments is necessary. The arguments' descriptions are:
```
    Argument        Description

    fixed           The encoding. This is dependent on the 'encoding' argument 
                    given to SeeDot. 
    
    testing         This is the argument in SeeDot specified by 'datasetType' field.
    
    regression      This is the type of problem ('classification' and 'regression'). 
                    This argument is inferred by SeeDot automatically.
    
    18000           This is equal to the argument specified in SeeDot's execution using
                    the 'numOutputs' field.
```

The executable is copied from `temp/Predictor` because that is the default output directory of SeeDot for target **x86**.

This executable takes its input from the `input/` directory (hence the use of `input` as the default for `out_dir` argument of `scale_image.py`). 

`X.csv` contains the floating-point input values; and `Y.csv`, consists of the correct integer labels (floating-point outputs) in case of classification (regression). However, since we are only concerned with the predicted output here, 
the contents of `Y.csv` are irrelevant. 

In the case of `face-2` and `face-4`, the input layer size is *76800* and the output 
has *18000* values (the number of columns in `X.csv` and `Y.csv` respectively). 

The output of `Predictor` is stored to `trace.txt`.

The executable dumps the execution stats and accuracy results in the `output/` directory. While it must exist, this directory is irrelevant to our discussion.



Now we construct the bounding boxes from `trace.txt`.

For that we run the below commands:
```
    python eval_fromquant.py --save_dir results/ --image_dir images/ --trace_file trace.txt
```

The images on which the prediction was carried out are read from the `images/` directory (which is the default for the `image_dir` field). The `image_dir` argument must be the same for both `scale_image.py` and `eval_fromquant.py`.

The images with bounding boxes drawn are stored in the `results/` directory (which is the default for the `save_dir` field).

`trace_file` field takes the location of `trace.txt` as the argument (which is `./trace.txt` by default).


Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT license.
